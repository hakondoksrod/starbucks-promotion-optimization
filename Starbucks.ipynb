{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Exercise: Starbucks\n",
    "<br>\n",
    "\n",
    "<img src=\"https://opj.ca/wp-content/uploads/2018/02/New-Starbucks-Logo-1200x969.jpg\" width=\"200\" height=\"200\">\n",
    "<br>\n",
    "<br>\n",
    " \n",
    "#### Background Information\n",
    "\n",
    "The dataset you will be provided in this portfolio exercise was originally used as a take-home assignment provided by Starbucks for their job candidates. The data for this exercise consists of about 120,000 data points split in a 2:1 ratio among training and test files. In the experiment simulated by the data, an advertising promotion was tested to see if it would bring more customers to purchase a specific product priced at $10. Since it costs the company 0.15 to send out each promotion, it would be best to limit that promotion only to those that are most receptive to the promotion. Each data point includes one column indicating whether or not an individual was sent a promotion for the product, and one column indicating whether or not that individual eventually purchased that product. Each individual also has seven additional features associated with them, which are provided abstractly as V1-V7.\n",
    "\n",
    "#### Optimization Strategy\n",
    "\n",
    "Your task is to use the training data to understand what patterns in V1-V7 to indicate that a promotion should be provided to a user. Specifically, your goal is to maximize the following metrics:\n",
    "\n",
    "* **Incremental Response Rate (IRR)** \n",
    "\n",
    "IRR depicts how many more customers purchased the product with the promotion, as compared to if they didn't receive the promotion. Mathematically, it's the ratio of the number of purchasers in the promotion group to the total number of customers in the purchasers group (_treatment_) minus the ratio of the number of purchasers in the non-promotional group to the total number of customers in the non-promotional group (_control_).\n",
    "\n",
    "$$ IRR = \\frac{purch_{treat}}{cust_{treat}} - \\frac{purch_{ctrl}}{cust_{ctrl}} $$\n",
    "\n",
    "\n",
    "* **Net Incremental Revenue (NIR)**\n",
    "\n",
    "NIR depicts how much is made (or lost) by sending out the promotion. Mathematically, this is 10 times the total number of purchasers that received the promotion minus 0.15 times the number of promotions sent out, minus 10 times the number of purchasers who were not given the promotion.\n",
    "\n",
    "$$ NIR = (10\\cdot purch_{treat} - 0.15 \\cdot cust_{treat}) - 10 \\cdot purch_{ctrl}$$\n",
    "\n",
    "For a full description of what Starbucks provides to candidates see the [instructions available here](https://drive.google.com/open?id=18klca9Sef1Rs6q8DW4l7o349r8B70qXM).\n",
    "\n",
    "Below you can find the training data provided.  Explore the data and different optimization strategies.\n",
    "\n",
    "#### How To Test Your Strategy?\n",
    "\n",
    "When you feel like you have an optimization strategy, complete the `promotion_strategy` function to pass to the `test_results` function.  \n",
    "From past data, we know there are four possible outomes:\n",
    "\n",
    "Table of actual promotion vs. predicted promotion customers:  \n",
    "\n",
    "<table>\n",
    "<tr><th></th><th colspan = '2'>Actual</th></tr>\n",
    "<tr><th>Predicted</th><th>Yes</th><th>No</th></tr>\n",
    "<tr><th>Yes</th><td>I</td><td>II</td></tr>\n",
    "<tr><th>No</th><td>III</td><td>IV</td></tr>\n",
    "</table>\n",
    "\n",
    "The metrics are only being compared for the individuals we predict should obtain the promotion â€“ that is, quadrants I and II.  Since the first set of individuals that receive the promotion (in the training set) receive it randomly, we can expect that quadrants I and II will have approximately equivalent participants.  \n",
    "\n",
    "Comparing quadrant I to II then gives an idea of how well your promotion strategy will work in the future. \n",
    "\n",
    "Get started by reading in the data below.  See how each variable or combination of variables along with a promotion influences the chance of purchasing.  When you feel like you have a strategy for who should receive a promotion, test your strategy against the test dataset used in the final `test_results` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /opt/anaconda3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.8/site-packages (from imblearn) (0.8.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.8/site-packages (1.3.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.19.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imblearn\n",
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044331</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2\n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2\n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2\n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2\n",
       "4   8       Yes         0   3  28.044331 -0.385883   1   1   2   2"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in packages\n",
    "from itertools import combinations\n",
    "\n",
    "from test_results import test_results, score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "# load in the data\n",
    "df_train = pd.read_csv('./training.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62970.972413</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>1.500662</td>\n",
       "      <td>29.973600</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1.679608</td>\n",
       "      <td>2.327643</td>\n",
       "      <td>2.502898</td>\n",
       "      <td>1.701694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36418.440539</td>\n",
       "      <td>0.110234</td>\n",
       "      <td>0.868234</td>\n",
       "      <td>5.010626</td>\n",
       "      <td>1.000485</td>\n",
       "      <td>0.466630</td>\n",
       "      <td>0.841167</td>\n",
       "      <td>1.117349</td>\n",
       "      <td>0.457517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.104007</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31467.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.591501</td>\n",
       "      <td>-0.905350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62827.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.979744</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94438.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.344593</td>\n",
       "      <td>0.826206</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>126184.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>50.375913</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID      purchase            V1            V2            V3  \\\n",
       "count   84534.000000  84534.000000  84534.000000  84534.000000  84534.000000   \n",
       "mean    62970.972413      0.012303      1.500662     29.973600      0.000190   \n",
       "std     36418.440539      0.110234      0.868234      5.010626      1.000485   \n",
       "min         1.000000      0.000000      0.000000      7.104007     -1.684550   \n",
       "25%     31467.250000      0.000000      1.000000     26.591501     -0.905350   \n",
       "50%     62827.500000      0.000000      2.000000     29.979744     -0.039572   \n",
       "75%     94438.750000      0.000000      2.000000     33.344593      0.826206   \n",
       "max    126184.000000      1.000000      3.000000     50.375913      1.691984   \n",
       "\n",
       "                 V4            V5            V6            V7  \n",
       "count  84534.000000  84534.000000  84534.000000  84534.000000  \n",
       "mean       1.679608      2.327643      2.502898      1.701694  \n",
       "std        0.466630      0.841167      1.117349      0.457517  \n",
       "min        1.000000      1.000000      1.000000      1.000000  \n",
       "25%        1.000000      2.000000      2.000000      1.000000  \n",
       "50%        2.000000      2.000000      3.000000      2.000000  \n",
       "75%        2.000000      3.000000      4.000000      2.000000  \n",
       "max        2.000000      4.000000      4.000000      2.000000  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Promotion    0\n",
       "purchase     0\n",
       "V1           0\n",
       "V2           0\n",
       "V3           0\n",
       "V4           0\n",
       "V5           0\n",
       "V6           0\n",
       "V7           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check invariant metric\n",
    "Check number of observations in control and treatment group to see if the groups are balanced and there is no statistically significant difference. The null hypothesis is that the groups are equal, and we must perform a two-tailed test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-score:  -0.6638066506192843\n",
      "p-value:  0.5068140685419046\n"
     ]
    }
   ],
   "source": [
    "n_obs = df_train.shape[0]\n",
    "n_control = df_train[df_train['Promotion'] == 'No'].shape[0]\n",
    "\n",
    "p = 0.5\n",
    "sd = np.sqrt(p * (1-p) * n_obs)\n",
    "\n",
    "z = ((n_control + 0.5) - p * n_obs) / sd\n",
    "\n",
    "print('z-score: ', z)\n",
    "print('p-value: ', 2 * sp.stats.norm.cdf(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value shows that the difference between groups is not statistically significant and that we must fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Icremental Response Rate (IRR)\n",
    "\n",
    "$$ IRR = \\frac{purch_{treat}}{cust_{treat}} - \\frac{purch_{ctrl}}{cust_{ctrl}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Promotion\n",
       "No     319\n",
       "Yes    721\n",
       "Name: purchase, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('Promotion').sum()['purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental response rate (IRR):  0.009454547819772702\n"
     ]
    }
   ],
   "source": [
    "#Calculate IRR\n",
    "n_control = df_train[df_train['Promotion'] == 'No'].shape[0]\n",
    "n_treat = df_train[df_train['Promotion'] == 'Yes'].shape[0]\n",
    "purch_control = df_train.query('Promotion == \"No\" and purchase == 1').shape[0]\n",
    "purch_treat = df_train.query('Promotion == \"Yes\" and purchase == 1').shape[0]\n",
    "\n",
    "IRR = purch_treat/n_treat - purch_control/n_control\n",
    "print('Incremental response rate (IRR): ', IRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An IRR of about 0.0095 indicates that the promotion results in additional purchases in the treatment group. The following hypothesis test will determine if the increase in purchase rate is statistically significant.\n",
    "\n",
    "The null hypothesis is that the IRR is less than or equal to 0, meaning that the promotion does not lead to increased sales. The alternative hypothesis is that the IRR is greater than 0.\n",
    "\n",
    "$$H_0: {IRR \\leq 0}$$\n",
    "$$H_1: {IRR > 0}$$\n",
    "\n",
    "Because we have two evaluation metrics, we have to use a correction to avoid making a type I error. Using the Bonferroni correction (dividing the alpha with number of evaluation metrics) gives us an alpha of 0.025\n",
    "\n",
    "$$\\alpha = 0.025$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-score:  12.468449461599388\n",
      "p-value:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Calculate proportion who made a purchase in each group and a pooled proportion\n",
    "prop_control = purch_control / n_control\n",
    "prop_treat = purch_treat / n_treat\n",
    "prop_total = (purch_control + purch_treat) / (n_control + n_treat)\n",
    "\n",
    "#Compute standard error\n",
    "se_prop = np.sqrt(prop_total * (1-prop_total) * (1/n_control + 1/n_treat))\n",
    "\n",
    "#Compute z-score\n",
    "z = (prop_treat - prop_control) / se_prop\n",
    "\n",
    "print('z-score: ', z)\n",
    "print('p-value: ', 1 - sp.stats.norm.cdf(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value of 0 tells us that there is definitely a statistically significant increase in purchase rate from the promotion, and we must therefore reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Incremental Revenue (NIR)\n",
    "\n",
    "$$ NIR = (10\\cdot purch_{treat} - 0.15 \\cdot cust_{treat}) - 10 \\cdot purch_{ctrl}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net incremental revenue:  -2334.5999999999995\n"
     ]
    }
   ],
   "source": [
    "#Calculate NIR\n",
    "NIR = (10 * purch_treat - 0.15 * n_treat) - 10 * purch_control\n",
    "print('Net incremental revenue: ', NIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NIR of -2334.6 indicates that Starbucks' cost of distributing the promotion exceeds the profits gained from the promotion. We will perform a hypothesis test to see if this observed NIR is statistically significant.\n",
    "\n",
    "The null hypothesis is that the NIR is smaller than or equal to 0, meaning that the promotion does not result in a net increase in revenue. The alternative hypothesis is that the NIR is greater than 0.\n",
    "\n",
    "$$H_0: {NIR \\leq 0}$$\n",
    "$$H_1: {NIR > 0}$$\n",
    "\n",
    "As the Bonferroni correction has been applied, the significance level is at 0.025\n",
    "\n",
    "$$\\alpha = 0.025$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use bootstrapping to simulate a distribution under the null hypothesis\n",
    "NIR_test = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    boot_sample = df_train.sample(20000, replace=True)\n",
    "    sample_purch_control = boot_sample.query('Promotion == \"No\" and purchase == 1').shape[0]\n",
    "    sample_purch_treat = boot_sample.query('Promotion == \"Yes\" and purchase == 1').shape[0]\n",
    "    sample_n_treat = boot_sample.query('Promotion == \"Yes\"').shape[0]\n",
    "    NIR_test.append((10 * sample_purch_treat - 0.15 * sample_n_treat) - 10 * sample_purch_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Simulate and plot a normal distribution under the null hypothesis\n",
    "null_distribution = np.random.normal(0, np.std(NIR_test), 10000)\n",
    "plt.hist(null_distribution, bins=50)\n",
    "plt.axvline(NIR, c='red')\n",
    "plt.title('Normal distribution under the null hypothesis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Compute p-value\n",
    "pval = (NIR<null_distribution).mean()\n",
    "print('p-value: ', pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed NIR value falls far below the normal distribution under the null hypothesis, and the p-value of 1 tells us that we must fail to reject the null hypothesis. This leads to the conclusion that sending the promotion to every customer will lead to a net loss for Starbucks.\n",
    "\n",
    "### Maximize IRR and NIR using modelling\n",
    "The next step is to create a model to maximize the two evaluation metrics. Using a machine learning classification algorithm we can predict which customers are the most likely to make a purchase upon receiving the promotion, and use this information to execute targeted promotion.\n",
    "\n",
    "As the data is quite unbalanced, with a very low proportion of customers making a purchase, I want to use an upsampling technique to balance out the data. I will use SMOTE (Synthetic Minority Oversampling Technique), which oversamples the minority class to create a balanced dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a column with 1 if the customer received promotion and made purchase, and 0 for all others\n",
    "df_train['response'] = df_train.apply(lambda row: 1 if (row['purchase'] == 1) and (row['Promotion'] == \"Yes\") else 0, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83813\n",
       "1      721\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.response.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y to split into training and test data\n",
    "X = df_train.drop(['ID', 'Promotion', 'purchase', 'response'], axis=1)\n",
    "y = df_train.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use upsampling to generate synthetic data \n",
    "X_train_upsample, y_train_upsample = SMOTE(random_state=42).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a classification model using Random Forest Classifier\n",
    "model_rfc = sk.ensemble.RandomForestClassifier(max_depth=10, random_state=42, n_estimators=1000)\n",
    "model_rfc.fit(X_train_upsample, y_train_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction on test set\n",
    "y_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Confusion matrix=====\n",
      " [[11927  4839]\n",
      " [   83    58]]\n",
      "=====Cross Validation Score (AUC)=====\n",
      " 0.872540697425977\n"
     ]
    }
   ],
   "source": [
    "print(\"=====Confusion matrix=====\\n\", confusion_matrix(y_test, y_preds))\n",
    "cv_score = cross_val_score(clf, X_train_upsample, y_train_upsample, cv=3, scoring='roc_auc')\n",
    "print(\"=====Cross Validation Score (AUC)=====\\n\", cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "    '''\n",
    "    INPUT \n",
    "    df - a dataframe with *only* the columns V1 - V7 (same as train_data)\n",
    "\n",
    "    OUTPUT\n",
    "    promotion_df - np.array with the values\n",
    "                   'Yes' or 'No' related to whether or not an \n",
    "                   individual should recieve a promotion \n",
    "                   should be the length of df.shape[0]\n",
    "                \n",
    "    Ex:\n",
    "    INPUT: df\n",
    "    \n",
    "    V1\tV2\t  V3\tV4\tV5\tV6\tV7\n",
    "    2\t30\t-1.1\t1\t1\t3\t2\n",
    "    3\t32\t-0.6\t2\t3\t2\t2\n",
    "    2\t30\t0.13\t1\t1\t4\t2\n",
    "    \n",
    "    OUTPUT: promotion\n",
    "    \n",
    "    array(['Yes', 'Yes', 'No'])\n",
    "    indicating the first two users would recieve the promotion and \n",
    "    the last should not.\n",
    "    '''    \n",
    "    y_pred = model_rfc.predict(df)\n",
    "    \n",
    "    promotion_yes_no = []\n",
    "    for pred in y_pred:\n",
    "        if pred == 0:\n",
    "            promotion_yes_no.append(\"No\")\n",
    "        if pred == 1:\n",
    "            promotion_yes_no.append(\"Yes\")\n",
    "    \n",
    "    promotion = np.asarray(promotion_yes_no)\n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  See how well your strategy worked on our test data below!\n",
      "\n",
      "Your irr with this strategy is 0.0175.\n",
      "\n",
      "Your nir with this strategy is 144.35.\n",
      "We came up with a model with an irr of 0.0188 and an nir of 189.45 on the test set.\n",
      "\n",
      " How did you do?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.017511709918127026, 144.35000000000002)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on how well your promotion_strategy will work in practice\n",
    "\n",
    "test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model using Random Forest classifier performed slightly worse than the benchmark. It's still a positive net result for Starbucks using targetet promotions based on this model, but I'd like to improve the model to increase the evaluation metrics.\n",
    "\n",
    "I want to try to use an XGBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.74629\tvalidation_1-auc:0.56087\n",
      "[1]\tvalidation_0-auc:0.77672\tvalidation_1-auc:0.56292\n",
      "[2]\tvalidation_0-auc:0.79425\tvalidation_1-auc:0.55668\n",
      "[3]\tvalidation_0-auc:0.79989\tvalidation_1-auc:0.56249\n",
      "[4]\tvalidation_0-auc:0.82484\tvalidation_1-auc:0.57844\n",
      "[5]\tvalidation_0-auc:0.83684\tvalidation_1-auc:0.57690\n",
      "[6]\tvalidation_0-auc:0.85561\tvalidation_1-auc:0.57172\n",
      "[7]\tvalidation_0-auc:0.86349\tvalidation_1-auc:0.58159\n",
      "[8]\tvalidation_0-auc:0.87377\tvalidation_1-auc:0.57987\n",
      "[9]\tvalidation_0-auc:0.87895\tvalidation_1-auc:0.57656\n",
      "[10]\tvalidation_0-auc:0.88772\tvalidation_1-auc:0.57869\n",
      "[11]\tvalidation_0-auc:0.88765\tvalidation_1-auc:0.57908\n",
      "[12]\tvalidation_0-auc:0.89013\tvalidation_1-auc:0.57737\n",
      "[13]\tvalidation_0-auc:0.89596\tvalidation_1-auc:0.57743\n",
      "[14]\tvalidation_0-auc:0.90293\tvalidation_1-auc:0.57731\n",
      "[15]\tvalidation_0-auc:0.90513\tvalidation_1-auc:0.57744\n",
      "[16]\tvalidation_0-auc:0.91277\tvalidation_1-auc:0.58042\n",
      "[17]\tvalidation_0-auc:0.91533\tvalidation_1-auc:0.58102\n",
      "[18]\tvalidation_0-auc:0.91649\tvalidation_1-auc:0.58173\n",
      "[19]\tvalidation_0-auc:0.91719\tvalidation_1-auc:0.58085\n",
      "[20]\tvalidation_0-auc:0.92155\tvalidation_1-auc:0.58321\n",
      "[21]\tvalidation_0-auc:0.92524\tvalidation_1-auc:0.58159\n",
      "[22]\tvalidation_0-auc:0.92566\tvalidation_1-auc:0.58105\n",
      "[23]\tvalidation_0-auc:0.92649\tvalidation_1-auc:0.58179\n",
      "[24]\tvalidation_0-auc:0.93642\tvalidation_1-auc:0.57827\n",
      "[25]\tvalidation_0-auc:0.94174\tvalidation_1-auc:0.57746\n",
      "[26]\tvalidation_0-auc:0.94295\tvalidation_1-auc:0.57574\n",
      "[27]\tvalidation_0-auc:0.94326\tvalidation_1-auc:0.57605\n",
      "[28]\tvalidation_0-auc:0.95006\tvalidation_1-auc:0.57518\n",
      "[29]\tvalidation_0-auc:0.95012\tvalidation_1-auc:0.57494\n",
      "[30]\tvalidation_0-auc:0.95408\tvalidation_1-auc:0.57177\n",
      "[31]\tvalidation_0-auc:0.95715\tvalidation_1-auc:0.57140\n",
      "[32]\tvalidation_0-auc:0.96282\tvalidation_1-auc:0.57161\n",
      "[33]\tvalidation_0-auc:0.96810\tvalidation_1-auc:0.57322\n",
      "[34]\tvalidation_0-auc:0.97032\tvalidation_1-auc:0.57342\n",
      "[35]\tvalidation_0-auc:0.97132\tvalidation_1-auc:0.57354\n",
      "[36]\tvalidation_0-auc:0.98225\tvalidation_1-auc:0.57594\n",
      "[37]\tvalidation_0-auc:0.98371\tvalidation_1-auc:0.57696\n",
      "[38]\tvalidation_0-auc:0.98728\tvalidation_1-auc:0.57979\n",
      "[39]\tvalidation_0-auc:0.98850\tvalidation_1-auc:0.57841\n",
      "[40]\tvalidation_0-auc:0.98848\tvalidation_1-auc:0.57868\n",
      "[41]\tvalidation_0-auc:0.99004\tvalidation_1-auc:0.57892\n",
      "[42]\tvalidation_0-auc:0.99203\tvalidation_1-auc:0.57583\n",
      "[43]\tvalidation_0-auc:0.99301\tvalidation_1-auc:0.57705\n",
      "[44]\tvalidation_0-auc:0.99384\tvalidation_1-auc:0.57904\n",
      "[45]\tvalidation_0-auc:0.99445\tvalidation_1-auc:0.57892\n",
      "[46]\tvalidation_0-auc:0.99496\tvalidation_1-auc:0.57892\n",
      "[47]\tvalidation_0-auc:0.99555\tvalidation_1-auc:0.57590\n",
      "[48]\tvalidation_0-auc:0.99581\tvalidation_1-auc:0.57467\n",
      "[49]\tvalidation_0-auc:0.99607\tvalidation_1-auc:0.57636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.3, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.175, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              silent=True, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build and train a model using xgboost\n",
    "eval_set = [(X_train_upsample, y_train_upsample), (X_test, y_test)]\n",
    "model_xgb = xgb.XGBClassifier(learning_rate = 0.175,\n",
    "                          max_depth = 7,\n",
    "                          min_child_weight = 5,\n",
    "                          objective = 'binary:logistic',\n",
    "                          seed = 42,\n",
    "                          gamma = 0.3,\n",
    "                          use_label_encoder=False,\n",
    "                          silent = True)\n",
    "model_xgb.fit(X_train_upsample, y_train_upsample, eval_set=eval_set, eval_metric='auc', verbose=True, early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "    '''\n",
    "    INPUT \n",
    "    df - a dataframe with *only* the columns V1 - V7 (same as train_data)\n",
    "\n",
    "    OUTPUT\n",
    "    promotion_df - np.array with the values\n",
    "                   'Yes' or 'No' related to whether or not an \n",
    "                   individual should recieve a promotion \n",
    "                   should be the length of df.shape[0]\n",
    "                \n",
    "    Ex:\n",
    "    INPUT: df\n",
    "    \n",
    "    V1\tV2\t  V3\tV4\tV5\tV6\tV7\n",
    "    2\t30\t-1.1\t1\t1\t3\t2\n",
    "    3\t32\t-0.6\t2\t3\t2\t2\n",
    "    2\t30\t0.13\t1\t1\t4\t2\n",
    "    \n",
    "    OUTPUT: promotion\n",
    "    \n",
    "    array(['Yes', 'Yes', 'No'])\n",
    "    indicating the first two users would recieve the promotion and \n",
    "    the last should not.\n",
    "    '''    \n",
    "    y_pred = model_xgb.predict(df)\n",
    "    \n",
    "    promotion_yes_no = []\n",
    "    for pred in y_pred:\n",
    "        if pred == 0:\n",
    "            promotion_yes_no.append(\"No\")\n",
    "        if pred == 1:\n",
    "            promotion_yes_no.append(\"Yes\")\n",
    "    \n",
    "    promotion = np.asarray(promotion_yes_no)\n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  See how well your strategy worked on our test data below!\n",
      "\n",
      "Your irr with this strategy is 0.0214.\n",
      "\n",
      "Your nir with this strategy is 313.25.\n",
      "We came up with a model with an irr of 0.0188 and an nir of 189.45 on the test set.\n",
      "\n",
      " How did you do?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.021353518813767878, 313.25)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on how well your promotion_strategy will work in practice\n",
    "\n",
    "test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performed much better. We now have an Incremental Response Rate (IRR) of 0.0214 and a Net Incremental Revenue of 313.25, which means both our evaluation metrics have outperformed the benchmark of 0.0188 and 189.45, respectively.\n",
    "\n",
    "Using this machine learning model, Starbucks would be able to perform targeted promotions to the customers who are likely to purchase the promoted product, instead of blindly distributing promotions to all customers, which would likely lead to a net loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
